{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Below is our feature matrix X and target variable y. Given this matrix and target matrix y, we should be able to predict 0 or 1 for new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.5192, 2.6487, 1.    ],\n",
       "       [2.4443, 1.5438, 1.    ],\n",
       "       [4.2409, 1.899 , 1.    ],\n",
       "       [5.8097, 2.4711, 1.    ],\n",
       "       [6.4423, 3.359 , 1.    ],\n",
       "       [5.8097, 3.2406, 1.    ],\n",
       "       [6.3917, 3.8128, 1.    ],\n",
       "       [6.8725, 4.4441, 1.    ],\n",
       "       [6.7966, 3.6747, 1.    ],\n",
       "       [8.163 , 4.7401, 1.    ],\n",
       "       [7.4038, 3.8917, 1.    ],\n",
       "       [7.6316, 4.602 , 1.    ],\n",
       "       [7.7581, 5.7265, 1.    ],\n",
       "       [6.5688, 4.9571, 1.    ],\n",
       "       [5.3543, 3.9903, 1.    ],\n",
       "       [4.4686, 3.0236, 1.    ],\n",
       "       [2.9757, 2.0568, 1.    ],\n",
       "       [2.4443, 1.2676, 1.    ],\n",
       "       [0.9008, 1.169 , 1.    ],\n",
       "       [2.1154, 1.7411, 1.    ],\n",
       "       [3.2794, 1.386 , 1.    ],\n",
       "       [4.165 , 1.5636, 1.    ],\n",
       "       [4.8482, 1.8793, 1.    ],\n",
       "       [3.33  , 2.7868, 1.    ],\n",
       "       [5.1518, 3.5563, 1.    ],\n",
       "       [6.2652, 4.0693, 1.    ],\n",
       "       [6.2652, 4.3849, 1.    ],\n",
       "       [7.2014, 1.5438, 1.    ],\n",
       "       [7.6569, 2.412 , 1.    ],\n",
       "       [6.1387, 1.7806, 1.    ],\n",
       "       [4.4939, 1.4057, 1.    ],\n",
       "       [4.8735, 2.6093, 1.    ],\n",
       "       [5.5314, 3.0828, 1.    ],\n",
       "       [6.0121, 3.9311, 1.    ],\n",
       "       [7.1508, 4.7598, 1.    ],\n",
       "       [7.7075, 5.3122, 1.    ],\n",
       "       [8.3148, 5.7068, 1.    ],\n",
       "       [8.5172, 5.1149, 1.    ],\n",
       "       [8.7449, 5.4109, 1.    ],\n",
       "       [7.8593, 3.8128, 1.    ],\n",
       "       [6.999 , 3.2406, 1.    ],\n",
       "       [5.5061, 2.9052, 1.    ],\n",
       "       [4.9241, 2.6882, 1.    ],\n",
       "       [6.6447, 3.8325, 1.    ],\n",
       "       [7.6822, 4.5428, 1.    ],\n",
       "       [8.0364, 5.7857, 1.    ],\n",
       "       [8.9221, 6.5552, 1.    ],\n",
       "       [7.8593, 5.253 , 1.    ],\n",
       "       [6.5941, 5.2333, 1.    ],\n",
       "       [6.0374, 4.7598, 1.    ],\n",
       "       [2.7227, 4.5822, 0.    ],\n",
       "       [1.9383, 3.6549, 0.    ],\n",
       "       [1.6852, 2.9841, 0.    ],\n",
       "       [4.3168, 4.4244, 0.    ],\n",
       "       [3.4312, 3.7536, 0.    ],\n",
       "       [5.4808, 5.2728, 0.    ],\n",
       "       [4.1144, 4.8387, 0.    ],\n",
       "       [3.2034, 4.4244, 0.    ],\n",
       "       [4.1144, 5.3911, 0.    ],\n",
       "       [5.1012, 6.0817, 0.    ],\n",
       "       [4.8988, 5.5687, 0.    ],\n",
       "       [5.9615, 6.4565, 0.    ],\n",
       "       [5.7591, 6.0028, 0.    ],\n",
       "       [6.6953, 6.7722, 0.    ],\n",
       "       [5.7338, 6.6538, 0.    ],\n",
       "       [6.6194, 7.1471, 0.    ],\n",
       "       [7.2014, 7.5219, 0.    ],\n",
       "       [7.2014, 6.8314, 0.    ],\n",
       "       [8.5931, 7.6206, 0.    ],\n",
       "       [7.7581, 7.1865, 0.    ],\n",
       "       [7.7581, 7.7784, 0.    ],\n",
       "       [5.1012, 7.6009, 0.    ],\n",
       "       [4.2156, 6.496 , 0.    ],\n",
       "       [3.4818, 5.8055, 0.    ],\n",
       "       [2.3684, 5.0163, 0.    ],\n",
       "       [1.7864, 4.1876, 0.    ],\n",
       "       [0.9008, 3.4379, 0.    ],\n",
       "       [0.9008, 5.7857, 0.    ],\n",
       "       [1.9636, 6.3382, 0.    ],\n",
       "       [1.4069, 4.9571, 0.    ],\n",
       "       [2.419 , 6.8511, 0.    ],\n",
       "       [2.8745, 6.0817, 0.    ],\n",
       "       [4.0132, 7.1668, 0.    ],\n",
       "       [4.6711, 7.226 , 0.    ],\n",
       "       [5.1771, 8.1533, 0.    ],\n",
       "       [6.2146, 7.4825, 0.    ],\n",
       "       [5.4555, 7.0484, 0.    ],\n",
       "       [5.9868, 8.5084, 0.    ],\n",
       "       [4.0891, 7.5417, 0.    ],\n",
       "       [2.3937, 7.2063, 0.    ],\n",
       "       [1.331 , 6.5355, 0.    ],\n",
       "       [1.7358, 5.4503, 0.    ],\n",
       "       [2.4443, 5.8449, 0.    ],\n",
       "       [3.1781, 4.8979, 0.    ],\n",
       "       [4.6711, 5.8055, 0.    ],\n",
       "       [5.9868, 7.3641, 0.    ],\n",
       "       [4.6711, 6.2592, 0.    ],\n",
       "       [7.581 , 8.3703, 0.    ],\n",
       "       [4.6457, 8.5676, 0.    ],\n",
       "       [4.6457, 8.1676, 0.    ]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "  \n",
    "def loadCSV(filename): \n",
    "    ''' \n",
    "    function to load dataset \n",
    "    '''\n",
    "    with open(filename,\"r\") as csvfile: \n",
    "        lines = csv.reader(csvfile) \n",
    "        dataset = list(lines) \n",
    "        for i in range(len(dataset)): \n",
    "            dataset[i] = [float(x) for x in dataset[i]]      \n",
    "    return np.array(dataset) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TASK1.1-The normalize() function takes argument a matrix X, and returns normalized matrix X\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize(X): \n",
    "    ''' \n",
    "    HINT:\n",
    "    np.min(Matrix, axis=0)===>returns a vector/array containing minimum value of each row.\n",
    "    np.max(Matrix, axis=0)===>returns a vector/array containing maximum value of each row.\n",
    "\n",
    "    '''\n",
    "    #Your task is to find minimum, maximum values of each column, and use it to normalize as in the manual\n",
    "    mins =              #mins is an array, it should contain minimum value of each column\n",
    "    maxs =              #maxs is an array, it should contain maximum value of each column \n",
    "    rng =               #Is an array containing range of each column. Range=max value- min value \n",
    "    norm_X =            #Use the normalization formula given in the manual \n",
    "    return norm_X \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TASK1.2-Return the sigmoid of Beta(transpose)*X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def logistic_func(beta, X): \n",
    "    ''' \n",
    "    Your task is to return the Sigmoid Function(h[x]) using basic algebra as defined in the manual. \n",
    "    '''\n",
    "    sigmoid=                      #Define the sigmoid function using the formula in the manual\n",
    "    return sigmoid \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART 2- Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2.1- Complete the Cost function as in the manual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cost_func(beta, X, y): \n",
    "    ''' \n",
    "    Your task is to return the cost function J as in the manual \n",
    "    '''\n",
    "    y = np.squeeze(y) \n",
    "    \n",
    "    final =                 #Compute Cost Function using the formula in the manual  \n",
    "    return np.mean(final) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#-----------------------------------------------PART-2 GRADIENT DESCENT----------------------------------------------------------\n",
    "#Refer the manual\n",
    "#The below function is already defined for you, use it in your grad_desc function \n",
    "def log_gradient(beta, X, y): \n",
    "    ''' \n",
    "    logistic gradient function \n",
    "    '''\n",
    "    first_calc = logistic_func(beta, X) - y.reshape(X.shape[0], -1) \n",
    "    final_calc = np.dot(first_calc.T, X) \n",
    "    return final_calc \n",
    "\n",
    "  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Task 2.2- Complete the Gardient Descent function as in the manual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Todo\n",
    "def grad_desc(X, y, beta, alpha=.01, converge_change=.001): \n",
    "    ''' \n",
    "    gradient descent function \n",
    "    '''\n",
    "    cost = cost_func(beta, X, y) \n",
    "    change_cost = 1\n",
    "    num_iter = 1\n",
    "    #We need to update Beta until our new cost function has reached minimum  \n",
    "    #Your task is to update Beta as describe in the manual\n",
    "    while(change_cost > converge_change): #When change_cost<converge_change we have reached a minimum and we will stop updating B\n",
    "        old_cost = cost \n",
    "        beta =         #Update beta;  \n",
    "        cost =         #Compute cost funtcion with updated beta(Call cost_func() with correct arguments) \n",
    "        change_cost =  #Difference between old cost and updated cost  \n",
    "        num_iter += 1\n",
    "      \n",
    "    return beta, num_iter  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#NOTHING TO DO HERE\n",
    "def pred_values(beta, X): \n",
    "    ''' \n",
    "    function to predict labels \n",
    "    '''\n",
    "    pred_prob = logistic_func(beta, X) \n",
    "    pred_value = np.where(pred_prob >= .5, 1, 0) \n",
    "    return np.squeeze(pred_value) \n",
    "\n",
    "def plot_reg(X, y, beta): \n",
    "    ''' \n",
    "    function to plot decision boundary \n",
    "    '''\n",
    "    # labelled observations \n",
    "    x_0 = X[np.where(y == 0.0)] \n",
    "    x_1 = X[np.where(y == 1.0)] \n",
    "      \n",
    "    # plotting points with diff color for diff label \n",
    "    plt.scatter([x_0[:, 1]], [x_0[:, 2]], c='b', label='y = 0') \n",
    "    plt.scatter([x_1[:, 1]], [x_1[:, 2]], c='r', label='y = 1') \n",
    "      \n",
    "    # plotting decision boundary \n",
    "    x1 = np.arange(0, 1, 0.1) \n",
    "    x2 = -(beta[0,0] + beta[0,1]*x1)/beta[0,2] \n",
    "    plt.plot(x1, x2, c='k', label='reg line') \n",
    "  \n",
    "    plt.xlabel('x1') \n",
    "    plt.ylabel('x2') \n",
    "    plt.legend() \n",
    "    plt.show() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#NOTHING TO DO HERE\n",
    "if __name__ == \"__main__\": \n",
    "    # load the dataset \n",
    "    dataset = loadCSV('final.csv') \n",
    "      \n",
    "    # normalizing feature matrix \n",
    "    X = normalize(dataset[:, :-1]) \n",
    "      \n",
    "    # stacking columns wth all ones in feature matrix \n",
    "    X = np.hstack((np.matrix(np.ones(X.shape[0])).T, X)) \n",
    "  \n",
    "    # response vector \n",
    "    y = dataset[:, -1] \n",
    "  \n",
    "    # initial beta values \n",
    "    beta = np.matrix(np.zeros(X.shape[1])) \n",
    "  \n",
    "    # beta values after running gradient descent \n",
    "    beta, num_iter = grad_desc(X, y, beta) \n",
    "  \n",
    "    # estimated beta values and number of iterations \n",
    "    print(\"Estimated regression coefficients:\", beta) \n",
    "    print(\"No. of iterations:\", num_iter) \n",
    "  \n",
    "    # predicted labels \n",
    "    y_pred = pred_values(beta, X) \n",
    "      \n",
    "    # number of correctly predicted labels \n",
    "    print(\"Correctly predicted labels:\", np.sum(y == y_pred)) \n",
    "      \n",
    "    # plotting regression line \n",
    "    plot_reg(X, y, beta) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
